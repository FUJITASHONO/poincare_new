深層畳み込みニューラルネットワークによる画像特徴抽出と転移学習中山英樹y y 東京大学大学院情報理工学系研究科Abstract 画像認識分野において，畳み込みニューラルネットワーク(CNN) は多くのタスクで驚異的な性能を達成し， 注目を集めている．特に，ImageNet に代表される大規模物体認識データセットを用いて学習させたCNN の中間層から抽出される特徴は非常に汎用性が高く，さまざまなドメインで利用可能であることが示されている． 本稿では，CNN の発展の歴史を概観したのち，CNN の特徴抽出器としての利用や，ne-tuning による転移学習の研究事例について紹介し，議論する． 1 はじめに一般物体認識(一般画像認識)[14] とは，制約のない実世界画像を言葉によって説明するタスクであり，古くから人工知能の究極的な目標の一つとされてきた(図1)． 現在，深層学習(ディープラーニング) はさまざまな機械学習タスクで驚異的な性能を実現しているが，画像認識分野における躍進は研究業界のみならず広く一般に大きなインパクトを与えている. 特に一般物体認識は，現在の深層学習および人工知能ブームの顔になっていると言っても過言ではないだろう． 深層学習の一般物体認識における大成功は，畳み込みニューラルネットワーク(CNN)[27] の構造がタスクに非常に良くはまったことに加え，質の良い大規模教師付きデータセットがいち早く整備され，研究コミュニティで共有されるようになったことに拠るところが大きい．これらのデータセットを用いて適切に学習させたCNN のパラメータは非常に汎用性が高く，強力な特徴抽出器として関連する他タスクへ転用可能であることが知られている．さらに，単に学習済みネットワーク(pre-trained network) を流用するだけでなく，これを初期状態としてさらに適用先タスクの訓練データで学習を進めることで，比較的少数の訓練データから極めて優れた性能が得られることが示されている．これらの転移学習法は，既に画像認識コミュニティにおいては必要不可欠な基本技術として確立しており，さまざまなpre-trained モデルがオープンソースで共有されている．以下では，これらの話題を中心に，CNN の歴史および最新動向について論じる． 2 画像認識における深層学習の歴史と発展2.1 畳み込みニューラルネットワーク(CNN) 深層学習の手法は数多く提案されており，画像認識分野においても様々なアプローチが検討されてきたが，現在最も顕著な成功を収めているのはCNNである．CNN は古典的な多層パーセプトロンの延長にあるが，脳の視覚野の構造における知見[18] を基に，ニューロン間の結合を局所に限定し層間の結合を疎にしていることを特徴とする．より具体的には，図2 に示すように，画像の局所的な特徴抽出を担う畳み込み層と，局所ごとに特徴をまとめあげるプーリング層(サブサンプリング層) を繰り返した構造となっている．畳み込みフィルタのパラメータは画像中のすべての場所で共有されるため，単純な全結合ネットワークに比べ大きくパラメータ数が減っている．また，プーリング層を交えることで，さらにパラメータ数を削減すると同時に，一般物体認識において必要不可欠である入力の平行移動に対する不変性を段階的に加えることができる. 直感的には， 入力の解像度を少しずつ落としながら異なるスケールで隣接する特徴の共起をとり，識別に有効な情報を選択的に上層へ渡していくネットワークであると解釈できる．このような畳み込み・プーリングの繰り返しによるアーキテクチャは日本発であり，福島らが開発したNeocognitron[10] が初出であった．その後，1990 年代にLeCun らによって誤差逆伝搬法による学習法が確立され[27]，現在にまで至るCNN の基本技術が確立された． 2000 年代に入ると，コンピュータビジョンのコミュニティでは一般物体認識の一大ブームが巻き起こり，CNN の応用も始まった[34, 33, 20]．しかし，この当時はデータ量・計算機パワーが共に十分ではなく，SIFT [30], HOG [4], bag-of-visual-words [3, 32] 等の経験的な特徴量ベースのシステムの方が優勢であった．例えば，一般物体認識で標準的なベンチマークとして長らく用いられてきたCaltech-101 [8] では数千枚程度の画像サンプルしか存在せず，入力からend-to-end で多数のネットワークパラメータを最適化することは困難であった． また，計算機の性能の面においても一般的な解像度の画像を扱うことは難しく，MNIST [26] (2828 ピクセル) やCIFAR-10/100 [24] (32  32 ピクセル) 等の極.... horse human horse human horse human (a) (b) (c) 図1 一般物体認識の主要なタスク． (a) 物体カテゴリ識別(Categorization). (b) 物体検出(De- tection). (c) 物体領域抽出(Semantic segmenta- tion). 端に小さい画像を用いた検証が主流であった．このため2000 年代においては，CNN は現実的な方法としてはほとんど注目されず，停滞の時期にあったと言える． 2.2 ImageNet Large-scale Visual Recognition Challenge 2010 年代に入ると，状況は大きく変化しはじめた． 特筆すべきは，ImageNet [5] という大規模教師付き画像データセットが公開されたことである．これは，自然言語処理分野で用いられる概念辞書であるWordNet [9] に合わせ，網羅的に各概念のサンプル画像を収集したものである．種となる画像は既存のテキストベース画像検索エンジンを用いて収集し，クラウドソーシングによって人海戦術でアノテーションを行うことにより， 大規模でありながら質の高い教師付きデータセットの構築に成功している．ImageNet は2015 年6 月現在， 21841 クラス，14,197,122 枚ものアノテーション済み画像データを有する1．2010 年からは，ImageNet のデータの一部(1000 クラス) を用いたコンペティション型ワークショップであるImageNet Large-scale Visual Recognition Challenge (ILSVRC) が毎年開催されており，2000 年代の研究の数百倍から数千倍もの規模のデータを自由に利用し，共通の土俵で競い合うことが可能になった． また，同時期に，GPU 技術の進歩により計算機能力の著しい発達があったことも忘れてはならない．このように，学習データ量・計算機資源の双方において，深層学習が真の力を発揮する土壌が整いつつあった． ブレークスルーとなったのは，2012 年のILSVRC におけるトロント大学のHinton らの躍進である．彼らは1http://www.image-net.org/ INPUT 32x32 Convolutions Convolutions Subsampling C1: feature maps 6@28x28 Subsampling S2: f. maps 6@14x14 S4: f. maps 16@5x5 C5: layer 120 C3: f. maps 16@10x10 F6: layer 84 Full connection Full connection Gaussian connections OUTPUT 10 図2 畳み込みニューラルネットワーク(LeNet- 5). 図は[27] より引用. 05 10 15 20 25 30 ILSVRC 2010 ILSVRC 2011 ILSVRC 2012 ILSVRC 2013 ILSVRC 2014 2015 (Baidu) Human 2015 (MS) 2015 (Google) Classification error (%) 28 26 16 6.6 12 5.98 5.1 4.94 4.82 図3 ILSVRC(1000 クラス物体識別タスク) のエラー率の推移． 8 層のCNN2 を用い，1000 クラス識別のエラー率で， 二位のチームに10%以上もの差をつけて圧勝し3，世界中の研究者に極めて大きな衝撃を与えた[25]．2013 年のILSVRC ではほぼすべてのシステムがCNN ベースに置き換わり，2014 年のコンテストでも更に大きく識別精度が改善している(図3)． 2014 年以降は開発の主役がWeb 系大企業に移り，それぞれしのぎを削っている状況である．ILSVRC 2014 ではGoogle がエラー率6.66% で優勝し[41]，その後Baidu, Microsoft, Google がそれぞれ5.98% [43], 4.94% [16], 4.82% [19] を達成している．同タスクにおける人間のエラー率は約5.1% であるとの報告もあり，2012 年のブレークスルー後わずか二年ほどで人間レベルへ到達する驚異的な発展を遂げている．なお，これまでのILSVRC の歴史は[39] に詳しく報告されているので，興味のある読者はぜひ参照されたい． 2.3 最新の研究動向ILSVRC 2012 を境に，コンピュータビジョンの研究コミュニティでは従来の特徴量ベースのアプローチから急速に深層学習(CNN) への乗り換えが進んだ．前述の通り，静止画のカテゴリ識別精度は既に人間と同レベルに至っていることから，現在は物体検出，物体領域抽出等のより難しい画像認識タスクへ焦点が移りつ2その後，第一著者のAlex Krizhevsky にちなみAlexNet と通称されるようになった． 3AlexNet を除くと，初回のILSVRC 2010 からのエラー率の改善は23% 程度に留まっており，頭打ちの傾向にあった．つある(図1). 物体検出においては，R-CNN [13] と呼ばれる手法が現在の主流である．前処理として物体の候補領域をあらかじめ多数取り出し，各候補領域についてCNN で物体の有無を識別することで検出を行う． R-CNN は一枚の画像について数千個の領域候補画像を識別する必要があるため，GPU を用いても画像一枚あたりの認識に数十秒を要する極めて計算コストの大きい手法であったが，その後より効率のよい手法が多く提案されている[15, 12, 38, 36]．最新の手法では，物体候補領域の生成から識別・矩形抽出までend-to-end で学習が行えるようになっている[38]．物体領域抽出はまだ発展途上であるが，やはりCNN をベースとしたものが中心的な役割を果たしている[29, 31]． これらの従来的な一般物体認識タスクに加え，画像の自然言語による説明文生成[22, 42] や，画像内容についての質疑応答[11, 37]，動画像の認識・要約[23, 6] など，さらに挑戦的なタスクも次々に取り組まれている． これらは，CNN をRecurrent neural network (RNN) [17] 等の別のネットワークと組み合わせることで実現されているが，いずれの場合もベースとなるCNN 自体の性能が極めて重要であることが知られている． 3 CNNを用いた転移学習ILSVRC 2012 の結果は衝撃を持って受け入れられ， ワークショップ当日は活発な議論がなされた．その際の重要な問題提起の一つは，ImageNet により訓練されたCNN はどの程度一般化できるのか，という問であった． すなわち，学習時(ImageNet) と異なるタスク・データセットへの知識転移の実現可能性についての議論である．果たしてその後の研究トレンドは一気にこの方向へ動き，わずか半年ほどでその高い汎用性が立証されると共に，利用法が確立された． 3.1 Pre-trained ネットワークによる特徴抽出CNN の最も簡単な利用方法は，学習済ネットワーク(pre-trained network) を固定し，純粋な特徴抽出器として用いる方法である(図4)．すなわち，入力画像をフィードフォワードし，適当な中間層の出力する値をそのまま特徴ベクトルとして用いるものであり，利用者側は深層学習やCNN に関する知識がなくとも手軽にその恩恵を受けることができる． Pre-trained network の利用においては，どの層から特徴抽出を行うかを考慮する必要がある．CNN では， 入力に近い層から識別層に近づくにつれ，徐々に低次の視覚的特徴からデータセットに特化した意味的な特徴に構造化されることが知られている[44]．したがって， 低すぎる層の特徴をとるとCNN の高い識別的構造の恩恵を受けることができず，逆に高すぎる層の特徴を選ぶと学習時のデータセットに特化しすぎてしまい，転… ........ ...... 1000 ........ ............ ............ ...... (SVM, etc.) .......... ...... 図4 Pre-trained network を用いた特徴抽出．… ........ ...... 1000 … 20 Fine-tuning ...... ............ .L ( ) i i L x , y ........ ............ ........ ...... 図5 Pre-trained network にne-tuning を加える場合の流れ． 移学習の性能が下がってしまうおそれがある．経験的には識別層の一つ二つ手前の全結合層を用いることが多い． 3.2 Fine-tuning による転移学習Pre-trained network をより積極的に活用する転移学習法として，対象タスクのデータセットを用いて更にネットワークの学習をすすめるne-tuning のアプローチも広く用いられている．図5 に示すように，pre-trained network の識別層だけを対象タスクのものにつけかえる．その他の部分は学習済みのパラメータを初期値として用い，誤差逆伝搬法による学習を進める．一般に， CNN の学習は初期値依存性が強く，特に訓練データが少ない場合はできるだけよい初期値を得ることが，過学習を防ぎよい学習結果を得るために重要である．対象タスクに関連したpre-trained network を適切に選択し初期値として用いてne-tuning を行うことで，フルスクラッチから学習するよりも格段によい結果を得られる場合が多い． なお，一般に深層学習においてne-tuning という言葉は，教師なし事前学習でネットワークを初期化したあと教師あり学習を進めるプロセスのことを指すが，現在画像認識の文脈においてはここで述べたように他の大規模データセットを用いた教師付き学習による初期化を指す場合が多いことに注意されたい4． 4現在，CNN では教師なし事前学習はほとんど用いられなくなっている．表1 PASCAL VOC 2007 における，ImageNet pre-trained network (AlexNet) を用いた転移学習アプローチの比較([1] より引用)．特徴抽出器としてのみ利用した場合(Pre-trained feature)， Fine-tuning を行った場合，およびフルスクラッチでCNN の学習行った場合の各検出成功率(%) を示す. Scratch 40.7 Pre-trained feature 45.5 Fine-tuning 54.1 表2 PASCAL VOC 2007 における，さまざまなImageNet pre-trained network をベースにne- tuning を行った際の検出成功率(%)([36] より引用)．物体検出手法はいずれもR-CNN を用いている. AlexNet 58.5 Small VGG 60.2 VGG-16 66.0 3.3 事例紹介Pre-trained network から得られる特徴量の利用については[7, 35] で詳しく調査され，ILSVRC のデータで学習したCNN から得られる特徴量は，物体認識・詳細画像カテゴリ識別・ドメイン適応・画像検索などのさまざまなタスクで非常に有効に働くことが報告されている．Fine-tuning のアプローチは[13] によって提案され， その後[1] によって詳しく調査された．表1 にその結果の一部を引用する．ここでは，AlexNet をpre-trained network として用い，物体検出のデータセットであるPASCAL VOC 2007 (20 クラス，約5 千枚の画像データセット) における検出成功率(mAP) を示している． このように，フルスクラッチからターゲットのデータで学習した場合や，pre-trained network の特徴量のみを用いた場合に比べ，ne-tuning が非常によい精度を達成していることが分かる． Pre-trained network を用いた転移学習では，元のモデル自体の性能も最終的なネットワークの精度に大きな影響を与える．2015 年現在は，ILSVRC 2014 でそれぞれ第二位，第一位であったOxford visual geom- etry group の16 層CNN (VGG-16) [40]，Google のGoogLeNet5 [41] がよく用いられるようになっている． 表2 に，[36] で報告された結果の一部を引用する．ターゲットのデータセットは同じくPASCAL VOC 2007 であり，R-CNN による物体検出においてベースとなるpre-trained network を変えて検出精度を評価したもの5初代CNN であるLeNet [27] にちなんで付けられた名前である． である．この結果が示す通り，AlexNet からVGG-16 にモデルを差し替えるだけで大きく精度向上していることが分かる．今後も，ILSVRC のカテゴリ識別タスクにおけるCNN の進化に伴い，標準的に用いられるpre-trained network は随時置き換わっていくものと思われる． なお，ImageNet を用いたpre-trained network は何にでも転用可能なわけではなく，ターゲットとするタスクがImageNet のカバーする領域に関連するものでなければ必ずしもよい結果は得られないことに注意が必要である．例えば，シーン認識タスクはImageNet が対象とする物体認識とはやや離れた関係にあるため，他のタスクに比べImageNet ベースのpre-trained network による転移学習の効果が薄いことが報告されている[7, 45] 6. 3.4 実践方法現在，画像認識分野における深層学習の標準的なOSS であるCaffe[21] にはmodel zoo というモデル共有の枠組みが用意されており，多くの研究者がそれぞれの手法で構築した学習済みネットワークを公開している．前述のAlexNet はもちろんのこと，network-in- network [28]，VGGnet [40], GoogLeNet [41] 等の最新の成果も次々と共有されており，自由に利用することが可能である7．Pre-trained network を用いた特徴抽出は，スクリプトを実行するだけで容易に行える環境が整っている．Fine-tuning を行う際はCNN の学習に関するノウハウが多少必要となるが，基本的にモデル自体は流用するためネットワーク構造に関するハイパーパラメータの設定は必要なく，フルスクラッチの学習と比較すると容易である．筆者の経験上，主に学習率の設定さえ気をつければ，十分によい結果が得られる場合が多い． 4 まとめと今後の展望本稿では，画像認識分野における深層学習の歴史と最新動向について俯瞰し，特にCNN の特徴抽出器としての利用や，ne-tuning による転移学習について中心的に紹介を行った．これらは既に手軽に利用可能な技術として確立しており，深層学習研究におけるロールモデルの一つになっていると言える． このようなCNN の一般物体認識における驚異的な成功を受け，画像認識こそが深層学習に最も向いたタスクであると見られる向きも少なくない．しかしながら筆者の意見では，これはタスクの性質というよりも， 静止画は比較的クラウドソーシングによるアノテーショ6シーン認識に特化したPlaces [45] と呼ばれる大規模データセットをMIT が公開しており，ImageNet 同様，数百万枚のラベル付き画像と学習済みネットワークが入手可能になっている． 7これらのモデルは，Torch7 [2] 等の他のOSS でも利用できる．ンが容易なため，ImageNet のような質のよい大規模教師付きデータセットがいち早く登場したことに負うところが大きいと考える．事実，現在研究業界で華々しい成果をあげているシステムは，元を辿ると何らかの形でImageNet や同規模のデータを利用しているものが大半であり，そこから外れるもの(例えば歩行者検出， 動画像認識等) では既存の特徴量と比較して必ずしも優れた成果をあげていないことに注意する必要があるだろう． 現在，画像認識分野はもとより，人工知能に関わるあらゆる分野においてより高度なタスクの実現へ向けて期待が高まっているが，手法に関する議論は盛んに為される一方で，それを支えるデータについては必ずしも十分に注意が払われていないように感じる．手法とデータは常に車の両輪の関係にあり，両者をバランスよく発展させることが，深層学習が次のブレークスルーを起こせるか否かの鍵であると考える． 参考文献[1] P. Agrawal, R. Girshick, and J. Malik. Analyzing the Performance of Multilayer Neural Networks for Object Recognition. In Proc. ECCV, 2014. [2] R. Collobert, K. Kavukcuoglu, and C. Farabet. Torch7: A matlab-like environment for machine learning. BigLearn, NIPS Workshop, pages 1{6, 2011. [3] G. Csurka, C. R. Dance, L. Fan, J. Willamowski, and C. Bray. Visual categorization with bags of keypoints. In Proc. ECCV Workshop on Statis- tical Learning in Computer Vision, 2004. [4] N. Dalal and B. Triggs. Histograms of Oriented Gradients for Human Detection. In Proc. CVPR, 2005. [5] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A large-scale hierarchical image database. In Proc. CVPR, pages 2{9, 2009. [6] J. Donahue, L. A. Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell. Long-term Recurrent Convolutional Networks for Visual Recognition and Description. In Proc. IEEE CVPR, 2015. [7] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. In Proc. ICML, 2014. [8] L. Fei-Fei, R. Fergus, and P. Perona. Learning generative visual models from few training exam- ples: An incremental bayesian approach tested on 101 object categories. Journal of Computer Vision and Image Understanding, 106(1):59{70, 2007. [9] C. Fellbaum. WordNet: An electronic lexical database. MIT Press, 1998. [10] K. Fukushima. Neocognitron: a self organizing neural network model for a mechanism of pat- tern recognition unaffected by shift in position. Biological Cybernetics, 36(4):93{202, 1980. [11] H. Gao, J. Mao, J. Zhou, Z. Huang, L. Wang, L. Angeles, and W. Xu. Are You Talking to a Machine? Dataset and Methods for Multilin- gual Image Question Answering. arXiv preprint arXiv:1505.05612, 2015. [12] R. Girshick. Fast R-CNN. arXiv preprint arXiv:1504.08083, 2015. [13] R. Girshick, J. Donahue, T. Darrell, U. C. Berke- ley, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmen- tation. In Proc. IEEE CVPR, 2014. [14] K. Grauman and B. Leibe. Visual object recogni- tion. Morgan & Claypool Publishers, 2011. [15] K. He, X. Zhang, S. Ren, and J. Sun. Spa- tial Pyramid Pooling in Deep Convolutional Net- works for Visual Recognition. arXiv preprint arXiv:1406.4729, 2014. [16] K. He, X. Zhang, S. Ren, and J. Sun. Delving Deep into Rectiers : Surpassing Human-Level Performance on ImageNet Classication. arXiv preprint arXiv:1502.01852, 2015. [17] S. Hochreiter and J. Schmidhuber. Long Short- term Memory. Neural Computation, 9(8):1{32, 1997. [18] D. Hubel and T. Wiesel. Receptive elds of single neurones in the cat's striate cortex. The Journal of physiology, 148:574{591, 1959. [19] S. Ioffe and C. Szegedy. Batch Normalization : Accelerating Deep Network Training by Re- ducing Internal Covariate Shift. arXiv preprint arXiv:1502.03167, 2015. [20] K. Jarrett, K. Kavukcuoglu, M. A. Ranzato, and Y. Lecun. What is the best multi-stage archi- tecture for object recognition? In Proc. IEEE ICCV, 2009. [21] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Dar- rell. Caffe : Convolutional Architecture for Fast Feature Embedding. In ACM Conference on Mul- timedia, pages 675{678, 2014. [22] A. Karpathy and L. Fei-Fei. Deep Visual-Semantic Alignments for Generating Image De- scriptions. In Proc. IEEE CVPR, 2015. [23] A. Karpathy and T. Leung. Large-scale Video Classication with Convolutional Neural Net- works. In Proceedings of 2014 IEEE Confer- ence on Computer Vision and Pattern Recogni- tion, pages 1725{1732, 2014. [24] A. Krizhevsky. Learning multiple layers of fea- tures from tiny images. Master's thesis, Toronto University, 2009. [25] A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet classication with deep convolutional neural networks. In Proc. NIPS, 2012. [26] Y. LeCun. The MNIST database of handwritten digits. [27] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proc. of the IEEE, pages 2278{2324, 1998. [28] M. Lin, Q. Chen, and S. Yan. Network in net- work. In Proc. ICLR, 2014. [29] J. Long, E. Shelhamer, and T. Darrell. Fully Con- volutional Networks for Semantic Segmentation. In Proc. IEEE CVPR, 2015. [30] D. Lowe. Object recognition from local scale- invariant features. In Proc. IEEE ICCV, pages 1150{1157, vol.2, 1999. [31] M. Mostajabi, P. Yadollahpour, and G. Shakhnarovich. Feedforward semantic segmentation with zoom-out features. In Proc. IEEE CVPR, 2015. [32] F. Perronnin, J. Sanchez, and T. Mensink. Im- proving the Fisher kernel for large-scale image classication. In Proc. ECCV, 2010. [33] M. A. Ranzato, F. J. Huang, Y. L. Boureau, and Y. LeCun. Unsupervised learning of invariant fea- ture hierarchies with applications to object recog- nition. In Proc. IEEE CVPR, 2007. [34] M. A. Ranzato, C. Poultney, S. Chopra, and Y. LeCun. Efficient learning of sparse representa- tions with an energy-based model. In Proc. NIPS, 2006. [35] A. S. Razavian, H. Azizpour, J. Sullivan, and S. Carlsson. CNN Features off-the-shelf : an As- tounding Baseline for Recognition. arXiv preprint arXiv:1403.6382, 2014. [36] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You Only Look Once : Unied , Real-Time Object Detection. arXiv preprint arXiv:1506.02640, 2015. [37] M. Ren, R. Kiros, and R. Zemel. Exploring Models and Data for Image Question Answering. arXiv preprint arXiv:1505.02074, 2015. [38] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN : Towards Real-Time Object Detection with Region Proposal Networks. arXiv preprint arXiv:1506.01497, 2015. [39] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei- Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision, pages 1{42, 2015. [40] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale Image Recoginition. In Intl. Conf. on Learning Repre- sentations (ICLR), 2015. [41] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going Deeper with Convolutions. In Proc. IEEE CVPR, 2015. [42] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan. Show and Tell : A Neural Image Caption Gener- ator. In Proc. IEEE CVPR, 2015. [43] R. Wu, S. Yan, Y. Shan, Q. Dang, and G. Sun. Deep Image : Scaling up Image Recognition. arXiv preprint arXiv:1501.02876, 2015. [44] M. D. Zeiler and R. Fergus. Visualizing and Un- derstanding Convolutional Networks. In Proc. ECCV, 2014. [45] B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva. Learning Deep Features for Scene Recognition using Places Database. In Proc. NIPS, 2014.